{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e52a8b2-6c93-46a1-93e7-ac8158ad4fd3",
   "metadata": {},
   "source": [
    "# Testing DNABERT embedding \n",
    "\n",
    "Here we will test if we can use the pre-trained DNABERT model to map DNA barcodes to a \"valid metric space\". Mainly, we want to contrast the results of 1-kNN accuracy with the 1D-CNN architecture, and stablish a baseline for later when we train our model from scratch. To my understaning, these are the parameters of the model:\n",
    "\n",
    "* Sequence Length: 512\n",
    "* Backbone: BERT_small\n",
    "* Proportion of the input masked: 15%\n",
    "* Hidden Layer Size: 768"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70600d59-4666-43da-a509-60b5183b80cb",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2193a148-85a6-46dd-812d-96594dc07823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "#Read dataset file\n",
    "dataset = pd.read_csv('../barcode_insect_database.tsv',sep='\\t')\n",
    "\n",
    "# Start filetring to get high quality Unseen sequences\n",
    "# In particular: Sequences from known species with more than 50 individuals per species.\n",
    "filtered = dataset[dataset['species_name'].notna()]\n",
    "s = filtered.groupby('species_name').sampleid.count()\n",
    "l = s[s > 50].index.to_list()\n",
    "\n",
    "#Sample 100 species at random to be unseen by our model for generalization.\n",
    "selected_species = random.sample(l, k=100)\n",
    "\n",
    "print(len(set(selected_species)))\n",
    "unseen = filtered[filtered['species_name'].isin(selected_species)]\n",
    "train = pd.concat([dataset, unseen, unseen]).drop_duplicates(keep=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ea7147-ed09-48d1-b484-a93f7e95dd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localscratch/pmillana.35030010.0/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils import seq2kmer\n",
    "\n",
    "#Ideally we would sample at most 10 sequences per sequence to reduce computational cost\n",
    "#without worrying for 'N's or '_'s\n",
    "\n",
    "#For now we need to restirct to sequences without gaps and '-'\n",
    "test = unseen[unseen['nucleotides'].apply(lambda x: x.count('-') ==0)\n",
    "                & unseen['nucleotides'].apply(lambda x: x.count('N') == 0)]\n",
    "\n",
    "#test = unseen.groupby('species_name').apply(lambda x: x.sample(10)).reset_index(drop=True)\n",
    "\n",
    "\n",
    "tokenized_test = []\n",
    "# Aply tokenization to sequences and save them to the dev file\n",
    "c = 0\n",
    "for i, row in test.iterrows():\n",
    "    barcode = row[\"nucleotides\"].strip()\n",
    "    tokenized_barcode = seq2kmer(barcode, 6)\n",
    "    tokenized_test.append([tokenized_barcode, random.randint(0,1)])  #I am including a fake label\n",
    "    c += 1\n",
    "    if c == 1000:\n",
    "        break\n",
    "    \n",
    "tokenized_test = pd.DataFrame(tokenized_test, columns=[\"sequence\", \"label\"])\n",
    "tokenized_test.to_csv(\"sample_data/ft/6/dev.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0805bab1-0051-494b-a7c9-dcb106c5873b",
   "metadata": {},
   "source": [
    "## Testing DNABERT out-of-the-box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98eeba1a-896f-46fa-9d6a-7964a6340f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the libraries\n",
    "import sys\n",
    "sys.path.append('/home/pmillana/projects/def-khill22/pmillana/DNABERT/src')   #This is where I installed my transformers library\n",
    "\n",
    "from utils import predict, set_seed\n",
    "import json\n",
    "\n",
    "\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import glue_compute_metrics as compute_metrics\n",
    "from transformers import glue_convert_examples_to_features as convert_examples_to_features\n",
    "from transformers import glue_output_modes as output_modes\n",
    "from transformers import glue_processors as processors\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    AlbertConfig,\n",
    "    AlbertForSequenceClassification,\n",
    "    AlbertTokenizer,\n",
    "    BertConfig,\n",
    "    BertForSequenceClassification,\n",
    "    BertForLongSequenceClassification,\n",
    "    BertForLongSequenceClassificationCat,\n",
    "    BertTokenizer,\n",
    "    DNATokenizer,\n",
    "    DistilBertConfig,\n",
    "    DistilBertForSequenceClassification,\n",
    "    DistilBertTokenizer,\n",
    "    FlaubertConfig,\n",
    "    FlaubertForSequenceClassification,\n",
    "    FlaubertTokenizer,\n",
    "    RobertaConfig,\n",
    "    RobertaForSequenceClassification,\n",
    "    RobertaTokenizer,\n",
    "    XLMConfig,\n",
    "    XLMForSequenceClassification,\n",
    "    XLMRobertaConfig,\n",
    "    XLMRobertaForSequenceClassification,\n",
    "    XLMRobertaTokenizer,\n",
    "    XLMTokenizer,\n",
    "    XLNetConfig,\n",
    "    XLNetForSequenceClassification,\n",
    "    XLNetTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "ALL_MODELS = sum(\n",
    "    (\n",
    "        tuple(conf.pretrained_config_archive_map.keys())\n",
    "        for conf in (\n",
    "            BertConfig,\n",
    "            XLNetConfig,\n",
    "            XLMConfig,\n",
    "            RobertaConfig,\n",
    "            DistilBertConfig,\n",
    "            AlbertConfig,\n",
    "            XLMRobertaConfig,\n",
    "            FlaubertConfig,\n",
    "        )\n",
    "    ),\n",
    "    (),\n",
    ")\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    \"dna\": (BertConfig, BertForSequenceClassification, DNATokenizer),\n",
    "    \"dnalong\": (BertConfig, BertForLongSequenceClassification, DNATokenizer),\n",
    "    \"dnalongcat\": (BertConfig, BertForLongSequenceClassificationCat, DNATokenizer),\n",
    "    \"bert\": (BertConfig, BertForSequenceClassification, BertTokenizer),\n",
    "    \"xlnet\": (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer),\n",
    "    \"xlm\": (XLMConfig, XLMForSequenceClassification, XLMTokenizer),\n",
    "    \"roberta\": (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer),\n",
    "    \"distilbert\": (DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer),\n",
    "    \"albert\": (AlbertConfig, AlbertForSequenceClassification, AlbertTokenizer),\n",
    "    \"xlmroberta\": (XLMRobertaConfig, XLMRobertaForSequenceClassification, XLMRobertaTokenizer),\n",
    "    \"flaubert\": (FlaubertConfig, FlaubertForSequenceClassification, FlaubertTokenizer),\n",
    "}\n",
    "                    \n",
    "TOKEN_ID_GROUP = [\"bert\", \"dnalong\", \"dnalongcat\", \"xlnet\", \"albert\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e2005-e174-4a4d-bcaf-0632d191a689",
   "metadata": {},
   "source": [
    "### Loading config file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11fe7e67-be7d-44ab-a6e4-482a642c92af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of argument class\n",
    "class get_args:\n",
    "    def __init__(self, **parameters):\n",
    "        self.__dict__.update(parameters)\n",
    "                 \n",
    "#Load .json file with arguments\n",
    "with open('predict_config.json') as f:\n",
    "    config_args = json.load(f)\n",
    "\n",
    "#print(config_args)\n",
    "args = get_args(**config_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185d8253-d302-4b36-a893-69653666db12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process rank: -1, device: cpu, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "============================================================\n",
      "<class 'transformers.tokenization_dna.DNATokenizer'>\n",
      "Predict using the following checkpoint: %s /home/pmillana/projects/def-khill22/pmillana/DNABERT/examples/ft/6\n",
      "finish loading examples\n",
      "number of processes for converting feature: 10\n",
      "1 processor started !\n",
      "2 processor started !\n",
      "3 processor started !\n",
      "4 processor started !\n",
      "5 processor started !\n",
      "6 processor started !\n",
      "7 processor started !\n",
      "8 processor started !\n",
      "9 processor started !\n",
      "10 processor started !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▌       | 32/125 [01:27<04:11,  2.71s/it]"
     ]
    }
   ],
   "source": [
    " # Setup CUDA, GPU & distributed training\n",
    "if args.local_rank == -1 or args.no_cuda:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "    args.n_gpu = torch.cuda.device_count()\n",
    "else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    device = torch.device(\"cuda\", args.local_rank)\n",
    "    torch.distributed.init_process_group(backend=\"nccl\")\n",
    "    args.n_gpu = 1\n",
    "args.device = device\n",
    "\n",
    "print(\n",
    "    \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\" %(\n",
    "    args.local_rank,\n",
    "    device,\n",
    "    args.n_gpu,\n",
    "    bool(args.local_rank != -1),\n",
    "    args.fp16)\n",
    ")\n",
    "\n",
    "# Set seed\n",
    "set_seed(args)\n",
    "\n",
    "# Prepare GLUE task\n",
    "args.task_name = args.task_name.lower()\n",
    "if args.task_name not in processors:\n",
    "    raise ValueError(\"Task not found: %s\" % (args.task_name))\n",
    "processor = processors[args.task_name]()\n",
    "args.output_mode = output_modes[args.task_name]\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)\n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "if args.local_rank not in [-1, 0]:\n",
    "    torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
    "\n",
    "args.model_type = args.model_type.lower()\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
    "\n",
    "if not args.do_visualize and not args.do_ensemble_pred:\n",
    "    config = config_class.from_pretrained(\n",
    "        args.config_name if args.config_name else args.model_name_or_path,\n",
    "        num_labels=num_labels,\n",
    "        finetuning_task=args.task_name,\n",
    "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
    "    )\n",
    "\n",
    "    config.hidden_dropout_prob = args.hidden_dropout_prob\n",
    "    config.attention_probs_dropout_prob = args.attention_probs_dropout_prob\n",
    "    if args.model_type in [\"dnalong\", \"dnalongcat\"]:\n",
    "        assert args.max_seq_length % 512 == 0\n",
    "    config.split = int(args.max_seq_length/512)\n",
    "    config.rnn = args.rnn\n",
    "    config.num_rnn_layer = args.num_rnn_layer\n",
    "    config.rnn_dropout = args.rnn_dropout\n",
    "    config.rnn_hidden = args.rnn_hidden\n",
    "\n",
    "    tokenizer = tokenizer_class.from_pretrained(\n",
    "        args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n",
    "        do_lower_case=args.do_lower_case,\n",
    "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
    "    )\n",
    "    model = model_class.from_pretrained(\n",
    "        args.model_name_or_path,\n",
    "        from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
    "        config=config,\n",
    "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
    "    )\n",
    "    print('finish loading model')\n",
    "\n",
    "    if args.local_rank == 0:\n",
    "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
    "\n",
    "    model.to(args.device)\n",
    "\n",
    "    print(\"Training/evaluation parameters %s\" %(args))\n",
    "\n",
    "\n",
    "# Prediction\n",
    "predictions = {}\n",
    "if args.do_predict and args.local_rank in [-1, 0]:\n",
    "    tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
    "    checkpoint = args.output_dir\n",
    "    print(\"Predict using the following checkpoint: %s\", checkpoint)\n",
    "    prefix = ''\n",
    "    model = model_class.from_pretrained(checkpoint)\n",
    "    model.to(args.device)\n",
    "    prediction = predict(args, model, tokenizer, prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6575ea-4530-4f81-9b91-4e039974c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = []\n",
    "for batch in prediction:\n",
    "    latent.extend(batch)\n",
    "\n",
    "latent = np.array(latent)\n",
    "print(latent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cbe6d2-ef3d-4c3b-99fe-d674fb9342d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import umap\n",
    "\n",
    "embedding = umap.UMAP(random_state=42).fit_transform(latent)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1) \n",
    "ax.set_title(\"Representation of the Latent Space\")\n",
    "ax.set_xlabel(\"UMAP 1\")\n",
    "ax.set_ylabel(\"UMAP 2\")\n",
    "\n",
    "ax.scatter(embedding[:, 0],\n",
    "           embedding[:, 1],\n",
    "           #c=y_true,\n",
    "           s=1,\n",
    "           cmap='Spectral')\n",
    "plt.show()\n",
    "fig.savefig(f'learned_representation.jpg', dpi =150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d8b19a-1461-418b-ab2e-896a8f2e1ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
